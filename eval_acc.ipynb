{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_ckpt_20000_OAI.pt\n"
     ]
    }
   ],
   "source": [
    "!ls /datadisk/tk/encoder_ckpt_20000_OAI.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval-acc-llama-oai: ## Eval kb adapter\n",
    "\tpython eval.py accuracy \\\n",
    "\t\t--seed 1607 \\\n",
    "\t\t--dataset_dir ${DATASET_DIR} \\\n",
    "\t\t--test_dataset synthetic_data \\\n",
    "\t\t--llm_base_dir '/home/llama_3_8b_ins' \\\n",
    "\t\t--model_dir '/home/kblam_llama_unified/kblam_unified' \\\n",
    "\t\t--encoder_dir '/datadisk/data/gcrbackup/experiments/kblam/exp_v0.1/stage1_lr_0.0001KBTokenLayerFreq3UseExtendedQAMultiEntities2UseOutlier1NoDuplicateKBSizedynamicSepQueryHeadUseDataAugFineTuneQueryKeyFromkey_synthetic_data_OAI_step_20000' \\\n",
    "\t\t--save_dir '/datadisk/data/gcrbackup/experiments/kblam/exp_v0.2_eval' \\\n",
    "\t\t--kb_layer_frequency ${KB_LAYER_FREQ} \\\n",
    "\t\t--ckpt_idx 20000 \\\n",
    "\t\t--lr 0 \\\n",
    "\t\t--kb_size 100 \\\n",
    "\t\t--no-fancy_instruction \\\n",
    "\t\t--encoder_spec oai \\\n",
    "\t\t--llm_type \"llama3\" \\\n",
    "\t\t--attn_save_dir \"/datadisk/kblamatt2\" \\\n",
    "\t\t--log_save_dir \"/datadisk/kblamatt2/acc_results\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/msalvaris/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from experiments.eval import eval_accuracy\n",
    "from transformers import AutoTokenizer, logging\n",
    "from kblam.kb_encoder import KBEncoder\n",
    "from kblam.models.kblam_config import KBLaMConfig\n",
    "from kblam.models.llama_model import KblamLlamaForCausalLM\n",
    "from kblam.models.phi3_model import KBLaMPhi3ForCausalLM\n",
    "from kblam.utils.data_utils import aug_row, generate_multi_entity_qa\n",
    "from kblam.utils.train_utils import get_kb_embd\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class ResultsCollector():\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset_dir,\n",
    "            encoder_path,\n",
    "            encoder_spec,\n",
    "            llm_base_dir,\n",
    "            llm_type,\n",
    "            model_path,\n",
    "            query_head_path,\n",
    "            test_dataset,\n",
    "            scale_factor=None,\n",
    "            kb_layer_frequency=-1):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.encoder_path = encoder_path\n",
    "        self.encoder_spec = encoder_spec\n",
    "        self.llm_base_dir = llm_base_dir\n",
    "        self.llm_type = llm_type\n",
    "        self.model_path = model_path\n",
    "        self.query_head_path = query_head_path\n",
    "        self.test_dataset = test_dataset\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "        encoder_model_spec = encoder_spec\n",
    "\n",
    "        validation_part_start_idx = 120000 if \"gpt\" in test_dataset else 0\n",
    "        self.dataset = json.load(open(os.path.join(dataset_dir, test_dataset) + \".json\"))[validation_part_start_idx: ]\n",
    "\n",
    "        self.key_embds = np.load(\n",
    "            os.path.join(dataset_dir, f\"{test_dataset}_{encoder_model_spec}_embd_key.npy\")\n",
    "        ).astype(\"float32\")[validation_part_start_idx: ]\n",
    "        self.value_embds = np.load(\n",
    "            os.path.join(dataset_dir, f\"{test_dataset}_{encoder_model_spec}_embd_value.npy\")\n",
    "        ).astype(\"float32\")[validation_part_start_idx: ]\n",
    "\n",
    "        if kb_layer_frequency == -1:\n",
    "            kb_layer_frequency = 3\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(llm_base_dir, trust_remote_code=True, padding_side=\"left\")\n",
    "        self.tokenizer.pad_token = \"^\"\n",
    "\n",
    "        if llm_type == \"llama3\":\n",
    "            if self.query_head_path:\n",
    "                self.model = KblamLlamaForCausalLM.from_pretrained(\n",
    "                    model_path,\n",
    "                    device_map=\"cuda\",\n",
    "                    torch_dtype=\"auto\",\n",
    "                    trust_remote_code=True,\n",
    "                )\n",
    "                self.model.load_query_head(self.query_head_path)\n",
    "            else:\n",
    "                self.model = KblamLlamaForCausalLM.from_pretrained(\n",
    "                    model_path,\n",
    "                    device_map=\"cuda\",\n",
    "                    torch_dtype=\"auto\",\n",
    "                    trust_remote_code=True,\n",
    "                )\n",
    "        else:\n",
    "            self.model = KBLaMPhi3ForCausalLM.from_pretrained(\n",
    "                model_path,\n",
    "                device_map=\"cuda\",\n",
    "                torch_dtype=\"auto\",\n",
    "                trust_remote_code=True,\n",
    "            )\n",
    "\n",
    "        self.model.generation_config.pad_token_id = self.tokenizer.pad_token_id\n",
    "        self.model.generation_config.eos_token_id = 128009\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "        kb_config = KBLaMConfig(\n",
    "            # sep_query_head=True,\n",
    "            kb_layer_frequency=kb_layer_frequency,\n",
    "            kb_scale_factor=self.scale_factor,\n",
    "            **self.model.config.to_dict(),\n",
    "        )\n",
    "        self.model.config = kb_config\n",
    "\n",
    "        self.encoder = KBEncoder(\n",
    "            encoder_name=encoder_spec.upper(),\n",
    "            projector_type=\"linear\",\n",
    "            endpoint_url=\"\",\n",
    "            out_dim=self.model.config.hidden_size * (self.model.config.num_hidden_layers // kb_layer_frequency + 1),\n",
    "            frozen_base_model=True,\n",
    "            projector_kwargs={\"mlp_depth\": 1, \"mlp_hidden_dim\": 512},\n",
    "            device=torch.device(\"cuda\"),\n",
    "        )\n",
    "\n",
    "        self.encoder.load_state_dict(torch.load(encoder_path))\n",
    "\n",
    "\n",
    "    def collect_results(self):\n",
    "        xs = [50, 100, 200, 400, 800, 1600, 3200, 6400]\n",
    "        for x in xs:\n",
    "            for trial in range(5):\n",
    "                trial_start_time = datetime.now()\n",
    "                # experiment_name = f\"test_synthetic_scale_factor_validation_only_100_{x}_triples_{trial}_trial\"\n",
    "                experiment_name = f\"nq_10000_scale_factor_100_{x}_triples_{trial}_trial\"\n",
    "                print(f\"starting {experiment_name}\")\n",
    "                eval_accuracy(\n",
    "                    dataset_dir=self.dataset_dir,\n",
    "                    test_dataset=self.test_dataset,\n",
    "                    encoder_spec=self.encoder_spec,\n",
    "                    kb_scale_factor=self.scale_factor,\n",
    "                    # encoder_path=\"/home/t-isazawat/azure-blob/xi-kb-llm/best_ckpt/encoder_ckpt_20000_OAI.pt\",\n",
    "                    encoder_path=\"/datadisk/tk/encoder_ckpt_20000_OAI.pt\",\n",
    "                    exp_config=experiment_name,\n",
    "                    fancy_question=False,\n",
    "                    kb_layer_frequency=3,\n",
    "                    kb_size=x,\n",
    "                    # llm_base_dir=\"/home/t-isazawat/azure-blob/xi-kb-llm/llama3_8b_ins\",\n",
    "                    llm_base_dir=self.llm_base_dir,\n",
    "                    llm_type=\"llama3\",\n",
    "                    # model_path=\"/home/t-isazawat/azure-blob/xi-kb-llm/llama3_8b_ins\",\n",
    "                    model_path=self.model_path,\n",
    "                    test_batch_size=min(x, 200),\n",
    "                    use_shift_match=False,\n",
    "                    # query_head_path=\"/home/t-isazawat/azure-blob/xi-kb-llm/best_ckpt/learned_query_head_20000_OAI.pth\",\n",
    "                    query_head_path=\"/datadisk/tk/learned_query_head_20000_OAI.pth\",\n",
    "                    save_dir=\"/datadisk/kblamatt2\",\n",
    "                    attn_save_dir=\"/datadisk/kblamatt2\",\n",
    "                    model=self.model,\n",
    "                    dataset=self.dataset,\n",
    "                    key_embds=self.key_embds,\n",
    "                    value_embds=self.value_embds,\n",
    "                    tokenizer=self.tokenizer,\n",
    "                    encoder=self.encoder,\n",
    "                )\n",
    "                print(f\"Took {datetime.now() - trial_start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/msalvaris/repos/KBLaM\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -r /datadisk/kblamatt2/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t\t\t  model-00004-of-00004.safetensors\n",
      "generation_config.json\t\t  model.safetensors.index.json\n",
      "model-00001-of-00004.safetensors  special_tokens_map.json\n",
      "model-00002-of-00004.safetensors  tokenizer.json\n",
      "model-00003-of-00004.safetensors  tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls /home/llama_3_8b_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE MODEL: /datadisk/tk/llama3_8b_ins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|                                                                                                                        | 0/4 [00:00<?, ?it/s]/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.embed_tokens.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.0.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.1.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.2.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.3.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.4.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.5.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.6.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.7.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.8.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  25%|████████████████████████████                                                                                    | 1/4 [00:00<00:00,  5.33it/s]/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.9.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.10.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.11.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.12.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.13.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.14.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.15.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.16.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.17.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.18.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.19.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  50%|████████████████████████████████████████████████████████                                                        | 2/4 [00:00<00:00,  5.53it/s]/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.20.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.21.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.22.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.23.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.24.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.25.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.26.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.27.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.28.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.29.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.30.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards:  75%|████████████████████████████████████████████████████████████████████████████████████                            | 3/4 [00:00<00:00,  5.52it/s]/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.layers.31.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "/home/msalvaris/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:2400: UserWarning: for model.norm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.56it/s]\n",
      "Some weights of LlamaModel were not initialized from the model checkpoint at /datadisk/tk/llama3_8b_ins and are newly initialized: ['model.layers.0.self_attn.score_shift', 'model.layers.1.self_attn.score_shift', 'model.layers.10.self_attn.score_shift', 'model.layers.11.self_attn.score_shift', 'model.layers.12.self_attn.score_shift', 'model.layers.13.self_attn.score_shift', 'model.layers.14.self_attn.score_shift', 'model.layers.15.self_attn.score_shift', 'model.layers.16.self_attn.score_shift', 'model.layers.17.self_attn.score_shift', 'model.layers.18.self_attn.score_shift', 'model.layers.19.self_attn.score_shift', 'model.layers.2.self_attn.score_shift', 'model.layers.20.self_attn.score_shift', 'model.layers.21.self_attn.score_shift', 'model.layers.22.self_attn.score_shift', 'model.layers.23.self_attn.score_shift', 'model.layers.24.self_attn.score_shift', 'model.layers.25.self_attn.score_shift', 'model.layers.26.self_attn.score_shift', 'model.layers.27.self_attn.score_shift', 'model.layers.28.self_attn.score_shift', 'model.layers.29.self_attn.score_shift', 'model.layers.3.self_attn.score_shift', 'model.layers.30.self_attn.score_shift', 'model.layers.31.self_attn.score_shift', 'model.layers.4.self_attn.score_shift', 'model.layers.5.self_attn.score_shift', 'model.layers.6.self_attn.score_shift', 'model.layers.7.self_attn.score_shift', 'model.layers.8.self_attn.score_shift', 'model.layers.9.self_attn.score_shift']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.45s/it]\n",
      "Some weights of KblamLlamaForCausalLM were not initialized from the model checkpoint at /datadisk/tk/llama3_8b_ins and are newly initialized: ['model.layers.0.self_attn.q_proj_new.weight', 'model.layers.0.self_attn.score_shift', 'model.layers.1.self_attn.q_proj_new.weight', 'model.layers.1.self_attn.score_shift', 'model.layers.10.self_attn.q_proj_new.weight', 'model.layers.10.self_attn.score_shift', 'model.layers.11.self_attn.q_proj_new.weight', 'model.layers.11.self_attn.score_shift', 'model.layers.12.self_attn.q_proj_new.weight', 'model.layers.12.self_attn.score_shift', 'model.layers.13.self_attn.q_proj_new.weight', 'model.layers.13.self_attn.score_shift', 'model.layers.14.self_attn.q_proj_new.weight', 'model.layers.14.self_attn.score_shift', 'model.layers.15.self_attn.q_proj_new.weight', 'model.layers.15.self_attn.score_shift', 'model.layers.16.self_attn.q_proj_new.weight', 'model.layers.16.self_attn.score_shift', 'model.layers.17.self_attn.q_proj_new.weight', 'model.layers.17.self_attn.score_shift', 'model.layers.18.self_attn.q_proj_new.weight', 'model.layers.18.self_attn.score_shift', 'model.layers.19.self_attn.q_proj_new.weight', 'model.layers.19.self_attn.score_shift', 'model.layers.2.self_attn.q_proj_new.weight', 'model.layers.2.self_attn.score_shift', 'model.layers.20.self_attn.q_proj_new.weight', 'model.layers.20.self_attn.score_shift', 'model.layers.21.self_attn.q_proj_new.weight', 'model.layers.21.self_attn.score_shift', 'model.layers.22.self_attn.q_proj_new.weight', 'model.layers.22.self_attn.score_shift', 'model.layers.23.self_attn.q_proj_new.weight', 'model.layers.23.self_attn.score_shift', 'model.layers.24.self_attn.q_proj_new.weight', 'model.layers.24.self_attn.score_shift', 'model.layers.25.self_attn.q_proj_new.weight', 'model.layers.25.self_attn.score_shift', 'model.layers.26.self_attn.q_proj_new.weight', 'model.layers.26.self_attn.score_shift', 'model.layers.27.self_attn.q_proj_new.weight', 'model.layers.27.self_attn.score_shift', 'model.layers.28.self_attn.q_proj_new.weight', 'model.layers.28.self_attn.score_shift', 'model.layers.29.self_attn.q_proj_new.weight', 'model.layers.29.self_attn.score_shift', 'model.layers.3.self_attn.q_proj_new.weight', 'model.layers.3.self_attn.score_shift', 'model.layers.30.self_attn.q_proj_new.weight', 'model.layers.30.self_attn.score_shift', 'model.layers.31.self_attn.q_proj_new.weight', 'model.layers.31.self_attn.score_shift', 'model.layers.4.self_attn.q_proj_new.weight', 'model.layers.4.self_attn.score_shift', 'model.layers.5.self_attn.q_proj_new.weight', 'model.layers.5.self_attn.score_shift', 'model.layers.6.self_attn.q_proj_new.weight', 'model.layers.6.self_attn.score_shift', 'model.layers.7.self_attn.q_proj_new.weight', 'model.layers.7.self_attn.score_shift', 'model.layers.8.self_attn.q_proj_new.weight', 'model.layers.8.self_attn.score_shift', 'model.layers.9.self_attn.q_proj_new.weight', 'model.layers.9.self_attn.score_shift']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/msalvaris/repos/KBLaM/src/kblam/models/llama_model.py:689: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  learned_query_heads = torch.load(ckpt_dir)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned query heads loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2651083/3584050049.py:103: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.encoder.load_state_dict(torch.load(encoder_path))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# dataset_dir = \"/home/t-isazawat/kblam_rebuttal_files/synthetic_perturbed\"\n",
    "# test_dataset = \"synthetic_perturbed\"\n",
    "# model_dir = \"/home/t-isazawat/azure-blob/xi-kb-llm/llama3_8b_ins\"\n",
    "# base_dir = \"/home/t-isazawat/azure-blob/xi-kb-llm/llama3_8b_ins\"\n",
    "# query_head_path = \"/home/t-isazawat/azure-blob/xi-kb-llm/best_ckpt/learned_query_head_20000_OAI.pth\"\n",
    "# encoder_path = \"/home/t-isazawat/azure-blob/xi-kb-llm/best_ckpt/encoder_ckpt_20000_OAI.pt\"\n",
    "\n",
    "# dataset_dir = \"/datadisk/tk/dataset\"\n",
    "# test_dataset = \"gpt_data\"\n",
    "\n",
    "dataset_dir = \"/datadisk/data/gcrbackup/oai_embd\"\n",
    "test_dataset = \"synthetic_data\"\n",
    "\n",
    "model_dir = \"/kblam_llama_unified/kblam_unified\"\n",
    "base_dir = \"/datadisk/tk/llama3_8b_ins\"\n",
    "query_head_path = \"/datadisk/tk/learned_query_head_20000_OAI.pth\"\n",
    "# query_head_path = None\n",
    "encoder_path = \"/datadisk/tk/encoder_ckpt_20000_OAI.pt\"\n",
    "\n",
    "collector = ResultsCollector(\n",
    "    dataset_dir,\n",
    "    encoder_path,\n",
    "    \"oai\",\n",
    "    base_dir,\n",
    "    \"llama3\",\n",
    "    base_dir,\n",
    "    query_head_path,\n",
    "    test_dataset,\n",
    "    scale_factor=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting nq_10000_scale_factor_100_50_triples_0_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_0_trial_31.npy\n",
      "[\"^^^<|start_header_id|>user<|end_header_id|> What is the description of Durga's Defense Portfolio?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Durga's Defense Portfolio is a fund that’s got your back when it comes to education and skills.<|eot_id|>^^^^^^^\", '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Digital Surrealism?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Digital Surrealism is a genre that uses digital tools to create fantastical, otherworldly images.<|eot_id|>^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the objectives of Brick & Mortar Melodies?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Brick & Mortar Melodies is to provide readers with inspiration and practical advice for a stylish life.<|eot_id|>^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of TidalWave Clownfish?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of TidalWave Clownfish is to make education engaging for children.<|eot_id|>^^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of GourmetGears Ltd.?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of GourmetGears Ltd. is to create a more connected and automated world through IoT technology.<|eot_id|>^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Petalithia Grace?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Petalithia Grace is provide skills-based training, offer certification courses, and track learning progress.<|eot_id|>^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the purpose of PlurkAgharta?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of PlurkAgharta is to offer a peaceful retreat for those seeking a return to rural life and nature.<|eot_id|>^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Tau Terrace?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Tau Terrace is to provide a stylish and relaxing atmosphere for socializing.<|eot_id|>^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Classy Cougar?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Classy Cougar is to delight food enthusiasts with gourmet options.<|eot_id|>^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of High-Rise Harmony?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of High-Rise Harmony is a music streaming service dedicated to indie artists.<|eot_id|>^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.02), np.float64(0.08))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.02), np.float64(0.08))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.04), np.float64(0.12))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(1.0), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.02), np.float64(0.12))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.02), np.float64(0.16))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.04), np.float64(0.14))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.02), np.float64(0.14))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.02), np.float64(0.12))\n",
      "Took 0:00:02.723452\n",
      "starting nq_10000_scale_factor_100_50_triples_1_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_1_trial_31.npy\n",
      "['^^<|start_header_id|>user<|end_header_id|> What is the description of Elara Starwhisper?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Elara Starwhisper is a tech entrepreneur specializing in AI development.<|eot_id|>^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the description of Elysia Starfall?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Elysia Starfall is a wildlife photographer capturing the sheer beauty of nature.<|eot_id|>^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Nu Nouveau?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Nu Nouveau is to promote mental health and well-being through mindfulness practices.<|eot_id|>^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Ravenna Starhunter?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Ravenna Starhunter is to push the boundaries of fashion and create bold, innovative designs.<|eot_id|>^^^', '^^<|start_header_id|>user<|end_header_id|> What is the description of Chiptune Chillout?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Chiptune Chillout is experience the moods of different weather patterns through music.<|eot_id|>^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Rosemary Rizzo?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Rosemary Rizzo is to share her love of music with the world.<|eot_id|>^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Theta-Kappa?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Theta-Kappa is to empower creators to produce professional-quality videos.<|eot_id|>^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Utopia Union?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Utopia Union is to create a dynamic environment for team collaboration and project meetings.<|eot_id|>^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the description of ElectroOboe?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of ElectroOboe is a digital instrument with a variety of synthesized sounds.<|eot_id|>^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Psi-Track?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Psi-Track is to support wildlife conservation efforts.<|eot_id|>^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.04), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.02), np.float64(0.14))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(1.0), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.02), np.float64(0.14))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.02), np.float64(0.18))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.04), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.02), np.float64(0.14))\n",
      "Took 0:00:01.508248\n",
      "starting nq_10000_scale_factor_100_50_triples_2_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_2_trial_31.npy\n",
      "['<|start_header_id|>user<|end_header_id|> What is the purpose of Drakonis the Infernal?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Drakonis the Infernal is to inspire and entertain through the art of dance.<|eot_id|>^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Fiat Falls?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Fiat Falls is foster community engagement, support local artists, provide diverse cultural experiences.<|eot_id|>^^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the purpose of Mount Shasta Retreat?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Mount Shasta Retreat is to provide a platform for emerging artists and foster cultural exchange.<|eot_id|>^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Galactic Frontier?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Galactic Frontier is to develop lighter and stronger materials for future missions.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Spectrum Summit?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Spectrum Summit is a mountain resort with skiing and snowboarding facilities and winter activities.<|eot_id|>^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Evergreen Estates?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Evergreen Estates is to create a nurturing and supportive environment for elderly residents.<|eot_id|>^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Charles Darwin?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Charles Darwin is a versatile content management system for bloggers.<|eot_id|>^^^^^^^^^^^^^^^^^', '^<|start_header_id|>user<|end_header_id|> What is the description of Chipotle Chukar?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Chipotle Chukar is a versatile kitchen knife that makes cooking a joy.<|eot_id|>^^^^^^^^^^^^', '<|start_header_id|>user<|end_header_id|> What is the objectives of StudyStem Hybrida?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of StudyStem Hybrida is to improve language proficiency, understand cultural nuances, and enhance communication skills.<|eot_id|>^^^^^^^', '<|start_header_id|>user<|end_header_id|> What is the description of Sylva-Serenade?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Sylva-Serenade is a virtual museum with interactive exhibits.<|eot_id|>^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.02), np.float64(0.12))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.04), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.02), np.float64(0.12))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(1.0), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.04), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.06), np.float64(0.14))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.04), np.float64(0.14))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.02), np.float64(0.16))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.02), np.float64(0.16))\n",
      "Took 0:00:01.802376\n",
      "starting nq_10000_scale_factor_100_50_triples_3_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_3_trial_31.npy\n",
      "['^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Solar Eagle?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Solar Eagle is to support individuals who need to stay connected on the go.<|eot_id|>^^^^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the description of Fides-Scrolls?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Fides-Scrolls is an educational platform with online courses, tutorials, and certification programs.<|eot_id|>^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the objectives of Fluidic Futurism?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Fluidic Futurism is to create movement and energy, exploring form and function relationships.<|eot_id|>^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Lament for Learning?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Lament for Learning is teach fundamental techniques, explore different styles, and encourage artistic expression.<|eot_id|>^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Hawking Horizons?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Hawking Horizons is to inspire readers to explore the world beyond the usual tourist spots.<|eot_id|>^^^^^^^^^^^', \"^^<|start_header_id|>user<|end_header_id|> What is the objectives of Lloigor's Shadow?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Lloigor's Shadow is to advance marine science and discovery.<|eot_id|>^^^^^^^^^^^^^^^^\", '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of OmicronLink?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of OmicronLink is support agile methodologies, improve collaboration, track progress.<|eot_id|>^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Arboris Bloom?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Arboris Bloom is a comprehensive gardening app with plant care tips.<|eot_id|>^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of GitHub Grit?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of GitHub Grit is to reduce carbon emissions and protect the environment.<|eot_id|>^^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Quantum Measurement?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Quantum Measurement is a guide to healthy living.<|eot_id|>^^^^^^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.04), np.float64(0.16))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.04), np.float64(0.14))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.02), np.float64(0.14))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(1.0), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.02), np.float64(0.16))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.02), np.float64(0.14))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.02), np.float64(0.12))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.02), np.float64(0.12))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.02), np.float64(0.14))\n",
      "Took 0:00:01.824373\n",
      "starting nq_10000_scale_factor_100_50_triples_4_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_50_triples_4_trial_31.npy\n",
      "['^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Stellar Summit?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Stellar Summit is a networking site for tech enthusiasts.<|eot_id|>^^^^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Plantify?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Plantify is to help users learn new languages and improve their communication skills.<|eot_id|>^^^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the purpose of Mythos Metabolism?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Mythos Metabolism is to offer high-quality skincare products that are both effective and environmentally friendly.<|eot_id|>^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of BlogBlaze?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of BlogBlaze is provide fast and reliable internet, ensure data protection, support multiple devices.<|eot_id|>^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Nova Citadel?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Nova Citadel is to ensure data integrity and privacy.<|eot_id|>^^^^^^^^^^^^^^^^^^', \"^^^<|start_header_id|>user<|end_header_id|> What is the description of Astral Drift?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Astral Drift is a remote outpost on the galaxy's edge, offering stunning starry views.<|eot_id|>^^^^^^^^\", '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Plaster Panther?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Plaster Panther is a smart thermostat for controlling your home climate.<|eot_id|>^^^^^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the description of Astro Appetite Ascent?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Astro Appetite Ascent is testing new materials for building spacecraft.<|eot_id|>^^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of GrandEagle Hospitality?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of GrandEagle Hospitality is provide educational resources, promote academic achievement, and support leadership development.<|eot_id|>^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the description of TumblrTambourine?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of TumblrTambourine is a durable and spacious backpack designed for travel and outdoor adventures.<|eot_id|>^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.04), np.float64(0.14))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.02), np.float64(0.12))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(1.0), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.06), np.float64(0.16))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.02), np.float64(0.1))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.06), np.float64(0.12))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.02), np.float64(0.1))\n",
      "Took 0:00:01.777240\n",
      "starting nq_10000_scale_factor_100_100_triples_0_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_0_trial_31.npy\n",
      "['^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Ocean Breeze Oasis?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Ocean Breeze Oasis is to create a dynamic cultural scene that enriches the community.<|eot_id|>^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of The Fashion Front?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of The Fashion Front is to provide a space for individuals to practice and improve their yoga skills.<|eot_id|>^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Ambient House?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Ambient House is to introduce African music to a wider audience.<|eot_id|>^^^^^^^^^^^^^^^', \"^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Scholar's Retreat?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Scholar's Retreat is to provide a tranquil outdoor space, encourage people to get active, and support nature conservation.<|eot_id|>^^^^^\", '^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Progressive Pages?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Progressive Pages is to help readers create beautiful digital artworks.<|eot_id|>^^^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Nebulon-5?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Nebulon-5 is to facilitate peaceful negotiations and alliances.<|eot_id|>^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Lightning Latte?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Lightning Latte is a collection of gourmet chocolate truffles for a sweet treat.<|eot_id|>^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Elara Nightshade?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Elara Nightshade is a marine biologist who’s all about coral reef ecosystems.<|eot_id|>^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of The Bookstore Buccaneers?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of The Bookstore Buccaneers is to ensure everyone has access to quality healthcare and support.<|eot_id|>^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the description of Retro-Futurism?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Retro-Futurism is a travel guide to uncovering hidden gems around the world.<|eot_id|>^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.01), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.01), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.01), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.99), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.01), np.float64(0.07))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.03), np.float64(0.08))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.03), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.01), np.float64(0.09))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.01), np.float64(0.08))\n",
      "Took 0:00:02.433327\n",
      "starting nq_10000_scale_factor_100_100_triples_1_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_1_trial_31.npy\n",
      "['^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Minimalist Fusion?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Minimalist Fusion is to create timeless pieces that appeal to a wide audience.<|eot_id|>^^^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the purpose of Celestial Drift?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Celestial Drift is to help users achieve a state of calm and relaxation through meditation.<|eot_id|>^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the purpose of Telegram Thunderclap?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Telegram Thunderclap is to help listeners achieve their personal and professional goals.<|eot_id|>^^^^^^^^^^^^^', '^<|start_header_id|>user<|end_header_id|> What is the objectives of The Organza Overture?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of The Organza Overture is to analyze technological advancements, to explore educational trends, to propose innovative solutions.<|eot_id|>^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of AppWhiz?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of AppWhiz is track tasks, set reminders, and provide time management tools.<|eot_id|>^^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the purpose of The Golden Harp?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of The Golden Harp is to promote environmental appreciation and mindfulness.<|eot_id|>^^^^^^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the description of UnityGrowth Network?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of UnityGrowth Network is an initiative focused on providing job training and employment opportunities for veterans.<|eot_id|>^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the description of Eldritch Expedition?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Eldritch Expedition is a versatile minivan with loads of cargo space and seating.<|eot_id|>^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Galactic Gateway?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Galactic Gateway is to help users achieve a balanced lifestyle.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the purpose of Coral Crown Clownfish?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Coral Crown Clownfish is to provide entertaining and educational theatrical productions.<|eot_id|>^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.03), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.01), np.float64(0.07))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(1.0), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.01), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.04), np.float64(0.09))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.01), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.01), np.float64(0.06))\n",
      "Took 0:00:02.347606\n",
      "starting nq_10000_scale_factor_100_100_triples_2_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_2_trial_31.npy\n",
      "['^^<|start_header_id|>user<|end_header_id|> What is the purpose of Necronomicon Networks?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Necronomicon Networks is to inspire a love of reading and help users discover their next favorite book.<|eot_id|>^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Mergeon?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Mergeon is a gas used in neon signs.<|eot_id|>^^^^^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Serenade Synth?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Serenade Synth is expand sonic palette, offer realistic instrument emulations, and support various genres.<|eot_id|>^^^^^^^^', '^<|start_header_id|>user<|end_header_id|> What is the description of Whimsical Whodunits?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Whimsical Whodunits is a collection of essays on modern fashion and style.<|eot_id|>^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of LumenGuard Harmony?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of LumenGuard Harmony is provide tailored exercise routines, track progress, and motivate users.<|eot_id|>^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Neural Network Art?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Neural Network Art is a method that uses neural networks to generate unique art.<|eot_id|>^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Forbidden Fitness?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Forbidden Fitness is to improve literacy rates and provide educational opportunities for all.<|eot_id|>^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Hertz Herald?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Hertz Herald is to keep the public updated on technological advancements.<|eot_id|>^^^^^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the objectives of Steampunk Narratives?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Steampunk Narratives is to captivate readers with stunning visuals and gripping stories.<|eot_id|>^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Delta Mu?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Delta Mu is a premium wine subscription service.<|eot_id|>^^^^^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.01), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.01), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(1.0), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.01), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.02), np.float64(0.11))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.01), np.float64(0.08))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.01), np.float64(0.07))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.02), np.float64(0.06))\n",
      "Took 0:00:02.431432\n",
      "starting nq_10000_scale_factor_100_100_triples_3_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_3_trial_31.npy\n",
      "['^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Glacier Glide?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Glacier Glide is to deliver a high-end and comfy driving experience for luxury SUV buyers.<|eot_id|>^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of GeneEthica?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of GeneEthica is to help individuals manage stress and improve their overall mental health.<|eot_id|>^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of HashtagHailstorm?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of HashtagHailstorm is to make healthy eating easy and convenient.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of FloraBot?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of FloraBot is create stunning visuals, streamline design processes, support creative projects.<|eot_id|>^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of LinkedLion?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of LinkedLion is to provide access to top-notch education, support career growth, and foster lifelong learning.<|eot_id|>^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Brookside Retreat?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Brookside Retreat is a modern wellness center offering a variety of health and wellness programs.<|eot_id|>^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Stellar Magnetism?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Stellar Magnetism is measure health improvements, compare activities, and suggest practices.<|eot_id|>^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Thunderstrike Echo?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Thunderstrike Echo is to provide laughter and insight into the complexities of love.<|eot_id|>^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the description of Veritas Aeterna?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Veritas Aeterna is a historical preservation project for local landmarks.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Sonata in Satin?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Sonata in Satin is a thrilling mystery novel set in a small coastal town.<|eot_id|>^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.02), np.float64(0.07))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.01), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(1.0), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.02), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.02), np.float64(0.09))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.01), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.02), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.02), np.float64(0.08))\n",
      "Took 0:00:02.538621\n",
      "starting nq_10000_scale_factor_100_100_triples_4_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_100_triples_4_trial_31.npy\n",
      "['^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Vinea Noctis?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Vinea Noctis is provide pet care advice, offer nutritional guidance, and support pet owners.<|eot_id|>^^^^^^', '^<|start_header_id|>user<|end_header_id|> What is the purpose of Sylvaflora Zenith?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Sylvaflora Zenith is to support users in maintaining mental health and balance.<|eot_id|>^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Plankton Pavilion?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Plankton Pavilion is promote mental clarity, reduce stress, and enhance spiritual growth.<|eot_id|>^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Hadrian-Hub?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Hadrian-Hub is ensure device compatibility, provide real-time monitoring, and support remote control.<|eot_id|>^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the description of The Badiouian Event?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of The Badiouian Event is a guide to practicing effective communication.<|eot_id|>^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Geometric Pop Art?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Geometric Pop Art is to foster a deeper connection between art and the environment.<|eot_id|>^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Jane Bioengineer?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Jane Bioengineer is discuss budgeting tips, review financial apps, and compare investment options.<|eot_id|>^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Kira Starfall?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Kira Starfall is to use music to unite people and spread harmony.<|eot_id|>^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the description of Post-Apocalyptic Fables?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Post-Apocalyptic Fables is a self-help book on mindfulness and meditation techniques to help you chill out.<|eot_id|>^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Astral Haven?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Astral Haven is to ensure food security and back agricultural development.<|eot_id|>^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.01), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.01), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.02), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.04), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(1.0), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.02), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.01), np.float64(0.09))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.01), np.float64(0.07))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.01), np.float64(0.07))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.08))\n",
      "Took 0:00:02.390657\n",
      "starting nq_10000_scale_factor_100_200_triples_0_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_0_trial_31.npy\n",
      "['^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Elegy Efficiency?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Elegy Efficiency is to help businesses optimize their operations.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Repository Ricercar?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Repository Ricercar is to help freelancers build a sustainable and fulfilling career, and to create a thriving freelance community.<|eot_id|>^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Helix Horizon?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^', \"^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Merchant's Mountain?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Merchant's Mountain is to support lifelong learning and intellectual growth.<|eot_id|>^^^^^^^^^^^^^^^^^\", '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of GitGuardian?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of GitGuardian is to inspire creativity and provide a platform for digital artists.<|eot_id|>^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Event Horizon Hats?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Event Horizon Hats is improve audio quality, enhance user comfort, and promote focus.<|eot_id|>^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Piledriver Pop?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of The Shunned House Institute?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of The Shunned House Institute is a dedicated center for linguistics and language studies.<|eot_id|>^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of VirtueCell?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of VirtueCell is an AI-powered chatbot for customer service.<|eot_id|>^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Neo-Classical?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Neo-Classical is to offer a timeless and sophisticated listening experience.<|eot_id|>^^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.005), np.float64(0.04))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.005), np.float64(0.03))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.005), np.float64(0.035))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.995), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.005), np.float64(0.03))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.02), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.005), np.float64(0.035))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.01), np.float64(0.04))\n",
      "Took 0:00:06.738173\n",
      "starting nq_10000_scale_factor_100_200_triples_1_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_1_trial_31.npy\n",
      "['^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Eternal Echoes?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Eternal Echoes is promote relaxation, reduce stress, and improve mental well-being.<|eot_id|>^^^^^^^^^^^^', '^^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Velvet Tide?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Velvet Tide is to offer a memorable and luxurious yachting experience.<|eot_id|>^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Frostfire Ridge?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Frostfire Ridge is a secret research center focused on climate change and emergency preparedness.<|eot_id|>^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of DomusVR?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of DomusVR is to provide accurate and fast translations, support multiple languages, and offer a user-friendly interface.<|eot_id|>^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of ExoGenesis?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of ExoGenesis is to advance the understanding of extraterrestrial life.<|eot_id|>^^^^^^^^^^^^^^', \"^^<|start_header_id|>user<|end_header_id|> What is the description of Pastorale of the Verdant Fields?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Pastorale of the Verdant Fields is a local farmers' market featuring fresh produce and handmade goods.<|eot_id|>^^^^^^^^\", '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of AirborneApe?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of AirborneApe is a versatile and stylish line of backpacks.<|eot_id|>^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Seraphina Cure?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Seraphina Cure is a talented musician with a captivating voice and enchanting performances.<|eot_id|>^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of ChimeraChews?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of ChimeraChews is to make getting your daily iron intake easy and enjoyable.<|eot_id|>^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Quantum Quay?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Quantum Quay is a bustling waterfront district with marinas, restaurants, and entertainment venues.<|eot_id|>^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.005), np.float64(0.03))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.005), np.float64(0.03))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.01), np.float64(0.04))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.005), np.float64(0.045))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.99), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.015), np.float64(0.055))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.01), np.float64(0.03))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.005), np.float64(0.03))\n",
      "Took 0:00:06.530058\n",
      "starting nq_10000_scale_factor_100_200_triples_2_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_2_trial_31.npy\n",
      "[\"^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Franklin's Frontier Inn?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Franklin's Frontier Inn is to connect guests with the natural beauty of the area and encourage a cozy stay.<|eot_id|>^^^^^^\", '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Augustus Air?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Augustus Air is to provide sustainable energy solutions.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Verdant Ventures?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Verdant Ventures is create sustainable communities, ensure quality construction, and provide modern amenities.<|eot_id|>^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Asset Aesthetics?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Asset Aesthetics is to help readers plan and enjoy their travel adventures.<|eot_id|>^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of MelodyMatrix?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of MelodyMatrix is deliver top-notch VR content, boost user engagement, and support various applications.<|eot_id|>^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the description of Skyscraper Skunk?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Skyscraper Skunk is a smart doorbell with video and audio capabilities.<|eot_id|>^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Turbo Tulip?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Turbo Tulip is to provide an effective and portable cardio workout tool.<|eot_id|>^^^^^^^^^^^^^', '^<|start_header_id|>user<|end_header_id|> What is the description of Time-Warped Sagas?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Time-Warped Sagas is a practical guide to financial planning and investment strategies. Secure your future, one step at a time.<|eot_id|>', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of The Madness Mansion?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of The Madness Mansion is to create a memorable venue for important occasions.<|eot_id|>^^^^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the objectives of Verdantia Brilliance?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Verdantia Brilliance is enhance skills, offer flexible learning, and provide expert instruction.<|eot_id|>^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.01), np.float64(0.03))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.005), np.float64(0.035))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.99), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.015), np.float64(0.05))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.01), np.float64(0.03))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.005), np.float64(0.035))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.015), np.float64(0.04))\n",
      "Took 0:00:06.132265\n",
      "starting nq_10000_scale_factor_100_200_triples_3_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_3_trial_31.npy\n",
      "['^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of PriceAlert?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of PriceAlert is to help users capture and preserve their travel memories.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Metaphysical Enigma?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Metaphysical Enigma is enhance cognitive skills, provide mental stimulation, and offer entertainment.<|eot_id|>^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Pax Virtutis?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Pax Virtutis is educate the public on organic farming, provide fresh produce to local food banks, and create green spaces in urban areas.<|eot_id|>^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Mystic Pulse?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Mystic Pulse is a music production company specializing in electronic and ambient genres.<|eot_id|>^^^^^^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the description of Honos et Dignitas?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Honos et Dignitas is a job training program for the unemployed.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of LuminaCore?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of LuminaCore is to provide a luxurious and effective skincare experience.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Tentacle Toning?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Tentacle Toning is to preserve the health and beauty of our oceans for future generations.<|eot_id|>^^^^^^^^^^^^', \"^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Cosmic Carousel?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Cosmic Carousel is a children's book series featuring magical adventures.<|eot_id|>^^^^^^^^^^^^^^^^^^\", '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Luminary Lane?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Luminary Lane is a vibrant street with art installations, street performances, and cultural events.<|eot_id|>^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Interstellar Insights?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Interstellar Insights is test recycling techniques, analyze waste composition, and implement management plans.<|eot_id|>^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.01), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.005), np.float64(0.03))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.015), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(1.0), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.01), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.02), np.float64(0.055))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.005), np.float64(0.03))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.01), np.float64(0.035))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.005), np.float64(0.035))\n",
      "Took 0:00:06.684536\n",
      "starting nq_10000_scale_factor_100_200_triples_4_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_200_triples_4_trial_31.npy\n",
      "['^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Sir Alaric the Defender?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Sir Alaric the Defender is to enhance our understanding of the natural world.<|eot_id|>^^^^^^^^^^', '^^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Fusion Forest?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Fusion Forest is to offer a scenic and adventurous destination for nature enthusiasts.<|eot_id|>^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Baryonium?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Baryonium is a rare earth element with high thermal conductivity.<|eot_id|>^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Floris Harmonia?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Floris Harmonia is to improve the well-being of clients through the therapeutic power of music.<|eot_id|>^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Urban Graffiti?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Urban Graffiti is to bring art to public spaces.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Appify Pro?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Appify Pro is to increase productivity and ensure timely project completion.<|eot_id|>^^^^^^^^^^^^^', '^^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Florence Treasury?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Florence Treasury is to protect and bring back coral reefs.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Radiant Strokes?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Radiant Strokes is promote the arts, provide a platform for underrepresented voices, and foster community engagement.<|eot_id|>^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Elysian Hall?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Elysian Hall is boost team collaboration, spark innovation, and streamline remote work.<|eot_id|>^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Active Acacia?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Active Acacia is replenish electrolytes, boost energy, and support muscle recovery.<|eot_id|>^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.005), np.float64(0.03))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.005), np.float64(0.03))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.005), np.float64(0.035))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.005), np.float64(0.04))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.995), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.01), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.005), np.float64(0.06))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.005), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.005), np.float64(0.03))\n",
      "Took 0:00:06.297493\n",
      "starting nq_10000_scale_factor_100_400_triples_0_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_0_trial_31.npy\n",
      "['^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of GreenWave Technologies?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of GreenWave Technologies is to promote healthy lifestyles and improve fitness tracking accuracy.<|eot_id|>^^^^^^^^^^^^^^^^^^^^', \"^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Harpy's Nest?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^^^^\", '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Helena Brickford?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Helena Brickford is a celebrated chef famous for her mind-blowing fusion cuisine.<|eot_id|>^^^^^^^^^^^^^^^^^', \"^^<|start_header_id|>user<|end_header_id|> What is the purpose of Ampere's Alcove?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Ampere's Alcove is host important client meetings and interviews.<|eot_id|>^^^^^^^^^^^^^^^^^^^^\", '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Quantum-Optic Networks?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Quantum-Optic Networks is to promote the appreciation and practice of pottery as an art form.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Delta Dimension?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of TempusSync?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of TempusSync is a language learning app with immersive experiences.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Celestial Drift?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Celestial Drift is to simplify the travel planning process and enhance the travel experience.<|eot_id|>^^^^^^^^^^^^^^^^^', \"^^<|start_header_id|>user<|end_header_id|> What is the objectives of Saraswati's Wisdom Hall?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Saraswati's Wisdom Hall is to support and promote emerging artists.<|eot_id|>^^^^^^^^^^^^^^^^^^^^\", '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Skyline Sculptures?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Skyline Sculptures is a collection of large-scale outdoor sculptures, enhancing public spaces with artistic installations.<|eot_id|>^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.0), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.005), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.99), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.0), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.01), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.01), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.02))\n",
      "Took 0:00:11.764781\n",
      "starting nq_10000_scale_factor_100_400_triples_1_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_1_trial_31.npy\n",
      "[\"^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Quantum Explorer?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Quantum Explorer is to enhance our understanding of black holes' nature and behavior.<|eot_id|>^^^^^^^^^^^^^^^^\", '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of The Echoing Horizon?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^', \"^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Nebula's Embrace?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Nebula's Embrace is to be a haven for nature lovers and researchers.<|eot_id|>^^^^^^^^^^^^^^^\", '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Abyssal Knight?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Steel Symphony?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Steel Symphony is to provide an immersive auditory experience for audiences.<|eot_id|>^^^^^^^^^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the description of Dr. Lucinda Visionaire?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Dr. Lucinda Visionaire is a leading sociologist studying urbanization trends.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Selene Nightfire?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Gothic Trance?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Gothic Trance is dark and mysterious vibes are the main themes.<|eot_id|>^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Fashion Funk?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Fashion Funk is to create a fun and lively atmosphere.<|eot_id|>^^^^^^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of VirtusNet?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of VirtusNet is to make art accessible to everyone and democratize creativity.<|eot_id|>^^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.005), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.005), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.005), np.float64(0.03))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.0), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.99), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.01), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.005), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.005), np.float64(0.02))\n",
      "Took 0:00:11.131912\n",
      "starting nq_10000_scale_factor_100_400_triples_2_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_2_trial_31.npy\n",
      "['^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Nu Wellness Co.?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Nu Wellness Co. is to revolutionize how people make and receive payments.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of RosalindReel?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of RosalindReel is a video-sharing platform for beauty and makeup tutorials.<|eot_id|>^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Roman Empire: Legacy?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Roman Empire: Legacy is compete in different sports, achieve high scores, and win tournaments.<|eot_id|>^^^^^^^^^^^^', '^^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Crime Castle?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Crime Castle is a serene room with floral decor and natural elements.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Coral Beak?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Coral Beak is to promote local wines and culinary experiences.<|eot_id|>^^^^^^^^^^^^^^^^^^', \"^^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of LinkedInite?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of LinkedInite is a fibrous, heat-resistant mineral. It's tough and can handle the heat.<|eot_id|>^^^^^^^^^^\", '^^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Beta Belle?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Beta Belle is luxury bath products for a spa-like experience at home.<|eot_id|>^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Trowel Trance?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Trowel Trance is to promote relaxation and mental clarity.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Nebula Castle?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Nebula Castle is a prestigious music academy offering courses in various instruments.<|eot_id|>^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of The Divine Bow?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of The Divine Bow is engage in space combat with futuristic ships.<|eot_id|>^^^^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.0), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.005), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.005), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.985), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.005), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.01), np.float64(0.04))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.0), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.005), np.float64(0.025))\n",
      "Took 0:00:11.180858\n",
      "starting nq_10000_scale_factor_100_400_triples_3_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_3_trial_31.npy\n",
      "['^^^^<|start_header_id|>user<|end_header_id|> What is the description of BlogOrbit?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of BlogOrbit is an innovative e-commerce platform with advanced marketing tools.<|eot_id|>^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Fleming Fabrics?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Fleming Fabrics is to elevate the cheese-tasting experience, making every bite a delight.<|eot_id|>^^^^^^^^', '^<|start_header_id|>user<|end_header_id|> What is the description of Filtered Fauvism?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Filtered Fauvism is a technique that emphasizes the use of bold, vibrant colors and simplified forms. Color explosion.<|eot_id|>^', \"^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Comet's Cove?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Comet's Cove is offer high-quality seafood, create a stylish dining experience, and support sustainable fishing.<|eot_id|>^^^^^^\", '^^<|start_header_id|>user<|end_header_id|> What is the objectives of Dr. CellFusion?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^', \"^<|start_header_id|>user<|end_header_id|> What is the objectives of Sartre's Silhouette?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Sartre's Silhouette is to capture the free-spirited essence of boho fashion. Live wild, dress wild.<|eot_id|>\", '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Omega Quantum?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Omega Quantum is accelerate scientific discovery, solve complex problems, and advance technology.<|eot_id|>^^^^^^^^^^^', \"^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Brickwork Basilisk?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Brickwork Basilisk is to ensure the stability of the earth's crust.<|eot_id|>^^^^^^^^^^^\", '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Sandstorm Whirl?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Sandstorm Whirl is energize listeners, promote physical activity, and inspire dance.<|eot_id|>^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the objectives of Bio-Illusionism?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.0), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.98), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.005), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.0), np.float64(0.035))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.005), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.02))\n",
      "Took 0:00:10.066727\n",
      "starting nq_10000_scale_factor_100_400_triples_4_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_400_triples_4_trial_31.npy\n",
      "['^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Shadowglide Heron?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Shadowglide Heron is to make your music listening and focus time way better.<|eot_id|>^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of FlavorJet?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Magnetar?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of GreenLeaf Biotech?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of GreenLeaf Biotech is a company specializing in advanced manufacturing tech to make production more efficient.<|eot_id|>^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Algorithmic Adagio?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Algorithmic Adagio is to inspire interest in science and technology.<|eot_id|>^^^^^^^^^^^^^^^^', \"^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Vishnu's Cosmic Dance?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Vishnu's Cosmic Dance is to unlock the secrets of animal communication.<|eot_id|>^^^^^^^^^^^^^^^^\", '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Jetstream Jingles?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Jetstream Jingles is improve posture, reduce back pain, and enhance productivity.<|eot_id|>^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Digital Noir?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Digital Noir is to evoke emotions and inspire love.<|eot_id|>^^^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Harmonia?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Harmonia is to preserve biodiversity and ensure the survival of endangered species.<|eot_id|>^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of The Silk Serenade?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.0), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.005), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.0), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.995), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.015), np.float64(0.035))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.01), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.02))\n",
      "Took 0:00:11.019895\n",
      "starting nq_10000_scale_factor_100_800_triples_0_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_0_trial_31.npy\n",
      "['^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of ElectroWave System?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of AstroFund Mission Alpha?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Foliage Brilliance?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Foliage Brilliance is to enable organizations to host successful events and connect with their audience through virtual means.<|eot_id|>^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Mu-Track?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Ontological Orbits?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Ontological Orbits is a blog about the latest advancements in artificial intelligence and machine learning.<|eot_id|>^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Fusion Foyer?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Fusion Foyer is cut down on travel time, promote eco-friendly transport, and make the ride fun.<|eot_id|>^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Alexander M. Pulse?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of SeaSurge Stocks?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of SeaSurge Stocks is connect volunteers with opportunities, support community engagement, and enhance the volunteering experience.<|eot_id|>^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Yield Yearning?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of SteemitStarling?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.005), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.99), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.0), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.0), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.01))\n",
      "Took 0:00:17.734823\n",
      "starting nq_10000_scale_factor_100_800_triples_1_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_1_trial_31.npy\n",
      "['^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Emberglow Finch?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Emberglow Finch is to attract birdwatchers and nature enthusiasts.<|eot_id|>^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Celestial Circuit?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Eclipse Lion?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Eclipse Lion is to offer a dedicated space for employees to dive into their creative talents and interests.<|eot_id|>^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Cavendish Corner?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Cavendish Corner is offer high-quality products, provide expert advice, and promote fitness.<|eot_id|>^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the description of Skyward Spire?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Cedric Brickforge?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Cedric Brickforge is to analyze social behavior in the digital age.<|eot_id|>^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the description of Ancient Indian Epics?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of KineticCore Nexus?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of KineticCore Nexus is look at trade data, assess economic growth, and propose trade policies.<|eot_id|>^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Willowyn Bliss?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Willowyn Bliss is provide tips for self-improvement, share motivational stories, and offer resources for personal growth.<|eot_id|>^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Zenith Innovations?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Zenith Innovations is save endangered species, restore natural habitats, and promote biodiversity.<|eot_id|>^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.005), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.97), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.005), np.float64(0.01))\n",
      "Took 0:00:17.191710\n",
      "starting nq_10000_scale_factor_100_800_triples_2_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_2_trial_31.npy\n",
      "['^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of CartSaver?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of CartSaver is to help users learn new languages through conversation with native speakers.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of ColorWave Creations?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Paradigm Pathway?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Paradigm Pathway is to foster a love of learning and intellectual growth.<|eot_id|>^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Dialectical Duster?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Arcadia Atrium?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Arcadia Atrium is to offer a serene and educational experience for visitors.<|eot_id|>^^^^^^^^^^^^^^^', \"^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of The Mason's Minuet?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of The Mason's Minuet is to introduce participants to regional wines.<|eot_id|>^^^^^^^^^^^^^^^^^^\", \"^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Jupiter's Jewels?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Jupiter's Jewels is developing cutting-edge medical imaging tech.<|eot_id|>^^^^^^^^^^^^^^^^^^^\", '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of The Divine Chariot?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of The Divine Chariot is to showcase the power of self-discovery and confidence.<|eot_id|>^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Dr. Lucinda Visionaire?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Dr. Lucinda Visionaire is to analyze the impact of urban growth on communities.<|eot_id|>^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Genomic Synergy?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.0), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.005), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.0), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.99), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.0), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.005))\n",
      "Took 0:00:20.254488\n",
      "starting nq_10000_scale_factor_100_800_triples_3_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_3_trial_31.npy\n",
      "['^^<|start_header_id|>user<|end_header_id|> What is the objectives of Ecliptic Spire?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Ecliptic Spire is to offer unique and stylish clothing.<|eot_id|>^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Marine Mythos?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Lucian Nightblade?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Lucian Nightblade is to raise awareness and drive social change.<|eot_id|>^^^^^^^^^^^^^', \"^^^<|start_header_id|>user<|end_header_id|> What is the purpose of The Outer Gods' Hall?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of The Outer Gods' Hall is conduct creative workshops and planning sessions.<|eot_id|>^^^^^^^^^^^^^\", '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Endorphin Expressionism?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of WaveWarrior Whale?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of SolarWave Panel?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Crimson Mirage?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Crimson Mirage is a culinary school offering professional and recreational cooking classes.<|eot_id|>^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Tentacle Toning?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Tentacle Toning is protect marine life, restore ocean habitats, and raise awareness.<|eot_id|>^^^^^^^^^', \"^^^^<|start_header_id|>user<|end_header_id|> What is the description of Rutherford's Retreat?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Rutherford's Retreat is a luxury retreat center offering workshops and wellness programs.<|eot_id|>^^^^^^^^^^^\"]\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.01), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.98), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.0), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.005))\n",
      "Took 0:00:18.202883\n",
      "starting nq_10000_scale_factor_100_800_triples_4_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_800_triples_4_trial_31.npy\n",
      "['^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Lemon Pepper Parrot?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Investment Incubus?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Queen Elizabeth the First?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Queen Elizabeth the First is an anthropologist who studies indigenous cultures.<|eot_id|>^^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Epistemological Eclair?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Eco-Sustainable Systems?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Eco-Sustainable Systems is to explore alternative agricultural practices and enhance crop yields.<|eot_id|>^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Bullish Bison?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of The Timeless Waltz?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of The Timeless Waltz is to introduce readers to the joy of ballroom dancing and promote physical activity.<|eot_id|>^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the description of Dreadful Deadlifts?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Dreadful Deadlifts is a non-profit organization focused on community development and support. Let’s build a better community.<|eot_id|>^^^^', \"^^^^<|start_header_id|>user<|end_header_id|> What is the description of Chic Chickadee?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Chic Chickadee is stylish children's clothing with playful designs.<|eot_id|>^^^^^^^^^^^^^^^\", '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Thalia Moonstone?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Thalia Moonstone is a talented chef specializing in vegan cuisine.<|eot_id|>^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.0), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.995), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.005), np.float64(0.025))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.0), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.015))\n",
      "Took 0:00:17.860252\n",
      "starting nq_10000_scale_factor_100_1600_triples_0_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_0_trial_31.npy\n",
      "['^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Petalium Apex?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Vedic Veggie Visions?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Sea Siren Sushi?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', \"^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Retailer's Trip?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Retailer's Trip is to support the film industry and provide a platform for filmmakers.<|eot_id|>^^^^^^^\", '^^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of GeneStar?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of GeneStar is to provide a unique and memorable travel experience for passengers.<|eot_id|>^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of NanoFuel Catalyst?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of BioBasilisk-X?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of BioBasilisk-X is to support both professional and amateur photographers.<|eot_id|>^^^^^^^^^^', '^^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Lunar Mission?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Cassian Nightshade?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Cassian Nightshade is to reduce crime rates, to mentor new detectives.<|eot_id|>^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Anantaraite?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.005), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.97), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.005), np.float64(0.01))\n",
      "Took 0:00:32.512993\n",
      "starting nq_10000_scale_factor_100_1600_triples_1_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_1_trial_31.npy\n",
      "['^^^<|start_header_id|>user<|end_header_id|> What is the description of Urban Uplift?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of HIIT Harmony?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of YamaYields?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Active Art?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of TideTamer?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^<|start_header_id|>user<|end_header_id|> What is the objectives of VultureVoyage?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of VultureVoyage is to educate viewers about significant historical events.<|eot_id|>^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Electro Ensemble?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Electro Ensemble is to make getting around the city easier and greener.<|eot_id|>^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of QuantumCore Systems?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of QuantumCore Systems is a company specializing in advanced agricultural tech to make farming more efficient.<|eot_id|>^^^^^^^', '^<|start_header_id|>user<|end_header_id|> What is the description of Marie Curie the Enlightened?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Marie Curie the Enlightened is a filmmaker who loves making documentaries about important issues.<|eot_id|>^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Roman Regimen?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.0), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.975), np.float64(0.995))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.005))\n",
      "Took 0:00:32.032796\n",
      "starting nq_10000_scale_factor_100_1600_triples_2_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_2_trial_31.npy\n",
      "['^^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Blossom Bounty?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Blossom Bounty is to help freelancers find work and grow their careers through an accessible and effective platform.<|eot_id|>^^^^^', '^^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Sirius Radiance?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Curie Cruiser?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Galactic Odyssey?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Zuse Binary?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Celestial Journey?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Olympus Heights?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Psi Pulse?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^', '^^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of The Velvet Pulse?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of The Velvet Pulse is a music streaming service offering curated playlists.<|eot_id|>^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Skepticism Suite?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.005), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.975), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.005), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.0))\n",
      "Took 0:00:35.925676\n",
      "starting nq_10000_scale_factor_100_1600_triples_3_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_3_trial_31.npy\n",
      "['^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Aurora Borealis?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^^', \"^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Patrician's Tome?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^^\", '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Goldenplume Heron?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Goldenplume Heron is to maintain healthy wetland ecosystems.<|eot_id|>^^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Suite Soul?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The description of Suite Soul is smooth and soulful tunes with a modern touch.<|eot_id|>^^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Tau Matrix?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Infinite Reflections?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Infinity Explorer?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of The Essence of Being?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Tapas Tones?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Graspium?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.005), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.97), np.float64(0.995))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.005), np.float64(0.02))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.015))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.005))\n",
      "Took 0:00:37.017015\n",
      "starting nq_10000_scale_factor_100_1600_triples_4_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_1600_triples_4_trial_31.npy\n",
      "['^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Bass Blaster?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Deep One Flights?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Cardio Colors?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Cardio Colors is to encourage bold and creative expression.<|eot_id|>^^^^^^^^^^^^^^^^^^^^', \"^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Mentor's Mountain?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Mentor's Mountain is provide high-quality accommodations, promote relaxation and adventure, create a memorable guest experience.<|eot_id|>^^^^^^^^^^\", '^^^<|start_header_id|>user<|end_header_id|> What is the purpose of SkySerenade Sax?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Dreamland Domain?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Dreamland Domain is to provide a versatile venue, support event planning, and attract diverse clientele.<|eot_id|>^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Autonomous Building Systems?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of Autonomous Building Systems is assess access, evaluate effectiveness, and propose changes.<|eot_id|>^^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Shannon Entropy?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Comet Quest?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Shadowveil Eclipse?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.005), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.98), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.005))\n",
      "Took 0:00:36.376405\n",
      "starting nq_10000_scale_factor_100_3200_triples_0_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_0_trial_31.npy\n",
      "['^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Beta Quantum?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Neo-Classical?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Synaptic Innovations?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Athletic Arena?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Orchid Whisper?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Aria Flux?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Infernium?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Shadow Sparrow?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Celestia Prime?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^', '^^^<|start_header_id|>user<|end_header_id|> What is the description of Rooftop Rocksteady?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.94), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.005), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.005))\n",
      "Took 0:01:00.702474\n",
      "starting nq_10000_scale_factor_100_3200_triples_1_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_1_trial_31.npy\n",
      "['^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Aquatic Academic?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Vortexium?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', \"^^<|start_header_id|>user<|end_header_id|> What is the purpose of Cleopatra's Couture?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Cleopatra's Couture is to revolutionize the tech industry with advanced AI applications and make life easier.<|eot_id|>^^\", \"^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Romulus' Legacy?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^\", '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Protean Park?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Acer Palmatum?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', \"^<|start_header_id|>user<|end_header_id|> What is the purpose of Y'golonac's Flame?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^\", '^<|start_header_id|>user<|end_header_id|> What is the description of Quantum Zippered Zoot Suits?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of MonsoonMatrix?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The objectives of MonsoonMatrix is provide property listings, offer virtual tours, and facilitate transactions.<|eot_id|>^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of BioPanther?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.005), np.float64(0.01))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.94), np.float64(1.0))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.0))\n",
      "Took 0:00:59.013281\n",
      "starting nq_10000_scale_factor_100_3200_triples_2_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_2_trial_31.npy\n",
      "['^^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Northern Lights?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Thunderous Echo?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Mythos Masters?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the description of Nebula Navigators?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of HealthHarpichord?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '<|start_header_id|>user<|end_header_id|> What is the purpose of Fantasia for the Fast Lane by Bugatti?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the description of Appify Pro?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^^<|start_header_id|>user<|end_header_id|> What is the objectives of Nightfall Sparrow?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Ethereal Geometry?<|eot_id|><|start_header_id|>assistant<|end_header_id|>I am sorry I cannot find relevant information in the KB.<|eot_id|>^^^^^^^^^^^^^^^^^^^^^', '^^^^^^<|start_header_id|>user<|end_header_id|> What is the purpose of Gospel Gumbo?<|eot_id|><|start_header_id|>assistant<|end_header_id|>The purpose of Gospel Gumbo is to provide a platform for theatrical expression and connect the community through the arts.<|eot_id|>^^^^^^^^^^^']\n",
      "ACC & TOP 5 ACC: 0 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 3 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 6 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 9 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 12 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 15 (np.float64(0.945), np.float64(0.995))\n",
      "ACC & TOP 5 ACC: 18 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 21 (np.float64(0.0), np.float64(0.005))\n",
      "ACC & TOP 5 ACC: 24 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 27 (np.float64(0.0), np.float64(0.0))\n",
      "ACC & TOP 5 ACC: 30 (np.float64(0.0), np.float64(0.0))\n",
      "Took 0:01:07.960571\n",
      "starting nq_10000_scale_factor_100_3200_triples_3_trial\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_0.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_1.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_2.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_3.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_4.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_5.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_6.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_7.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_8.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_9.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_10.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_11.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_12.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_13.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_14.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_15.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_16.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_17.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_18.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_19.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_20.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_21.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_22.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_23.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_24.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_25.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_26.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_27.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_28.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_29.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_30.npy\n",
      "SAVING /datadisk/kblamatt2 /datadisk/kblamatt2/nq_10000_scale_factor_100_3200_triples_3_trial_31.npy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcollector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 114\u001b[0m, in \u001b[0;36mResultsCollector.collect_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m experiment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnq_10000_scale_factor_100_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_triples_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_trial\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m \u001b[43meval_accuracy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkb_scale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# encoder_path=\"/home/t-isazawat/azure-blob/xi-kb-llm/best_ckpt/encoder_ckpt_20000_OAI.pt\",\u001b[39;49;00m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/datadisk/tk/encoder_ckpt_20000_OAI.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfancy_question\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkb_layer_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkb_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# llm_base_dir=\"/home/t-isazawat/azure-blob/xi-kb-llm/llama3_8b_ins\",\u001b[39;49;00m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_base_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_base_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# model_path=\"/home/t-isazawat/azure-blob/xi-kb-llm/llama3_8b_ins\",\u001b[39;49;00m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_shift_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# query_head_path=\"/home/t-isazawat/azure-blob/xi-kb-llm/best_ckpt/learned_query_head_20000_OAI.pth\",\u001b[39;49;00m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_head_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/datadisk/tk/learned_query_head_20000_OAI.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/datadisk/kblamatt2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_save_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/datadisk/kblamatt2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_embds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_embds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_embds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_embds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTook \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtrial_start_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/repos/KBLaM/experiments/eval.py:748\u001b[0m, in \u001b[0;36meval_accuracy\u001b[0;34m(dataset_dir, encoder_path, encoder_spec, exp_config, fancy_question, kb_layer_frequency, kb_scale_factor, kb_size, llm_base_dir, llm_type, model_path, test_batch_size, test_dataset, use_shift_match, query_head_path, save_dir, attn_save_dir, model, dataset, key_embds, value_embds, tokenizer, encoder)\u001b[0m\n\u001b[1;32m    745\u001b[0m kb_embedding_real \u001b[38;5;241m=\u001b[39m (kb_embedding_real[\u001b[38;5;241m0\u001b[39m], kb_embedding_real[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 748\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkb_kvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkb_embedding_real\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_attention_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_save_loc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_save_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_file_base_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs\u001b[38;5;241m.\u001b[39msqueeze(), skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28mprint\u001b[39m(outputs[:\u001b[38;5;241m10\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/transformers/generation/utils.py:1737\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1729\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1730\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1731\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1732\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1733\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1734\u001b[0m     )\n\u001b[1;32m   1736\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1737\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1751\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config) \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/transformers/generation/utils.py:2376\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2373\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2375\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2376\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2377\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2379\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2380\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2381\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2384\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/repos/KBLaM/src/kblam/models/llama_model.py:749\u001b[0m, in \u001b[0;36mKblamLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, kb_kvs, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, save_attention_weights, attention_save_loc, attention_file_base_name)\u001b[0m\n\u001b[1;32m    746\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 749\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkb_kvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkb_kvs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkb_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_attention_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_attention_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_save_loc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_save_loc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_file_base_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_file_base_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    767\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/repos/KBLaM/src/kblam/models/llama_model.py:522\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, kb_kvs, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, kb_config, save_attention_weights, attention_save_loc, attention_file_base_name)\u001b[0m\n\u001b[1;32m    506\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    507\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    508\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         attention_file_base_name,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 522\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkb_kvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkb_kvs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkb_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_attention_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_attention_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_save_loc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_save_loc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_file_base_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_file_base_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/repos/KBLaM/src/kblam/models/llama_model.py:370\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, kb_kvs, kb_config, save_attention_weights, attention_save_loc, attention_file_base_name)\u001b[0m\n\u001b[1;32m    367\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Rectangular Attention\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkb_kvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkb_kvs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkb_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_attention_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_attention_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_save_loc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_save_loc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_file_base_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_file_base_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/repos/KBLaM/src/kblam/models/llama_model.py:186\u001b[0m, in \u001b[0;36mKblamLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, kb_kvs, kb_config, save_attention_weights, attention_save_loc, attention_file_base_name, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\n\u001b[0;32m--> 186\u001b[0m     query_states_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\n\u001b[1;32m    188\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/kblam/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "collector.collect_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29096"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collector.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t-wangx/azure_blob/xi-kb-llm/outputs/ckpts/stage1_0__lr_0.0001KBTokenLayerFreq1UseExtendedQAMultiEntities2UseOutlier1NoDuplicateKBSizedynamicSepQueryHeadUseDataAugKeyFromkey_OAI_gpt_data_llama3_epoch_10000\n",
      "/home/t-wangx/azure_blob/xi-kb-llm/outputs/ckpts/stage1_0__lr_0.0001KBTokenLayerFreq1UseExtendedQAMultiEntities2UseOutlier1NoDuplicateKBSizedynamicSepQueryHeadUseDataAugFineTuneQueryKeyFromkey_gpt_data_OAI_epoch_10000\n"
     ]
    }
   ],
   "source": [
    "os.environ['SEP_QUERY_HEAD'] = 'TRUE'\n",
    "os.environ['LENGTH_INVARIANCE'] = ''\n",
    "# os.environ['SEP_QUERY_HEAD'] = ''\n",
    "encoder_model_spec = 'OAI'\n",
    "# train_dataset_name = 'avocado_new'\n",
    "train_dataset_name = 'gpt_data'\n",
    "epoch = 10000\n",
    "# lr = 0.0005\n",
    "lr = 0.0001\n",
    "extended_qa_spec = 'UseExtendedQA'\n",
    "outlier_spec = \"UseOutlier1\"\n",
    "# outlier_spec = \"\"\n",
    "multi_entity_string = \"MultiEntities2\"\n",
    "# multi_entity_string = \"\"\n",
    "# outlier_spec = \"\"\n",
    "kb_size_spec = 'KBSizedynamic'\n",
    "# kb_size_spec = 'KBSize50'\n",
    "# os.environ['SCALE_FACTOR'] = '40'\n",
    "os.environ['SCALE_FACTOR'] = ''\n",
    "duplicate_spec = \"NoDuplicate\"\n",
    "kb_layer_frequency = 1\n",
    "kb_layer_frequency_str = f'KBTokenLayerFreq{kb_layer_frequency}'\n",
    "# kb_layer_frequency_str=''\n",
    "# outlier_spec = ''\n",
    "key_src = 'key'\n",
    "\n",
    "llm_model_spec = '/home/t-wangx/llama_weights/llama3_8b_ins'\n",
    "print(f'/home/t-wangx/azure_blob/xi-kb-llm/outputs/ckpts/stage1_0__lr_{lr}{kb_layer_frequency_str}{extended_qa_spec}{multi_entity_string}{outlier_spec}{duplicate_spec}{kb_size_spec}SepQueryHeadUseDataAugKeyFrom{key_src}_{encoder_model_spec}_{train_dataset_name}_llama3_epoch_{epoch}')\n",
    "print( f'/home/t-wangx/azure_blob/xi-kb-llm/outputs/ckpts/stage1_0__lr_{lr}{kb_layer_frequency_str}{extended_qa_spec}{multi_entity_string}{outlier_spec}{duplicate_spec}{kb_size_spec}SepQueryHeadUseDataAugFineTuneQueryKeyFrom{key_src}_{train_dataset_name}_{encoder_model_spec}_epoch_{epoch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
